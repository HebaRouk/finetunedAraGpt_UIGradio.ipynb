{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HebaRouk/finetunedAraGpt_UIGradio.ipynb/blob/main/finetunedAraGpt_UIGradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preparation"
      ],
      "metadata": {
        "id": "m6qnoVEm9doX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "qGIG8kBTjhgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LsF784mfloe",
        "outputId": "a0781082-dd52-4100-8086-a70e2af43e38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ln -s drive/MyDrive/Aragpt40Epochs/ ./Ara\n",
        "#!ln -s drive/MyDrive/Colab\\ Notebooks/Aragpt40Epochs/ ./Ara"
      ],
      "metadata": {
        "id": "YRoW2XpahOj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install gpt-2-simple==0.7.1"
      ],
      "metadata": {
        "id": "ggTJ7xA_wriS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ccBkmLvhSZU8",
        "outputId": "0a301703-fd50-4894-ece7-e19f36270e52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ctC4S4UVSr4d",
        "outputId": "184185fe-a523-4aa3-c9df-f3c2f3424818"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Gradio\n",
            "  Downloading gradio-5.29.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<25.0,>=22.0 (from Gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from Gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from Gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from Gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.10.0 (from Gradio)\n",
            "  Downloading gradio_client-1.10.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from Gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from Gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from Gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from Gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from Gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from Gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from Gradio) (3.10.17)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from Gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from Gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from Gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from Gradio) (2.11.3)\n",
            "Collecting pydub (from Gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from Gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from Gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from Gradio)\n",
            "  Downloading ruff-0.11.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from Gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from Gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from Gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from Gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from Gradio) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from Gradio) (4.13.2)\n",
            "Collecting uvicorn>=0.14.0 (from Gradio)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->Gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->Gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->Gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->Gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->Gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->Gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->Gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->Gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->Gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->Gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->Gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->Gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->Gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->Gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->Gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->Gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->Gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->Gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->Gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->Gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->Gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->Gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->Gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->Gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->Gradio) (0.1.2)\n",
            "Downloading gradio-5.29.0-py3-none-any.whl (54.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.1/54.1 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.10.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.9/322.9 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m131.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, Gradio\n",
            "Successfully installed Gradio-5.29.0 aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-client-1.10.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.8 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip aragptFineTuned40EP.zip"
      ],
      "metadata": {
        "id": "qiyXGtQ5S4W2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!export CUDA_LAUNCH_BLOCKING=1"
      ],
      "metadata": {
        "id": "CsGo9DuStNi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, gc"
      ],
      "metadata": {
        "id": "sTt5ySwrwKsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load the model"
      ],
      "metadata": {
        "id": "zn1xW7Wx9qfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import gradio as gr\n",
        "import os\n",
        "\n",
        "#os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "# Load the fine-tuned model and tokenizer\n",
        "model_path = \"./Ara\"  # Update this path if needed\n",
        "#model_path = \"aubmindlab/aragpt2-base\"  # Update this path if needed\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
        "#model = model.to('cuda')\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "# Set the pad token to be the same as eos_token if not already set\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "80dlOFfRaUw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature 1:  Chapter by chapter generation"
      ],
      "metadata": {
        "id": "aHowwDlE91vM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_chapters =[]\n",
        "\n",
        "#Previous_chapters,\n",
        "# Function to generate a chapter based on user input\n",
        "def generate_first_chapter( topic):#, chapter2, chapter3):\n",
        "    global output_chapters\n",
        "    output_chapters =[]\n",
        "    print(len(output_chapters))\n",
        "    #topic = chapter1  # Using Chapter 1 input as topic\n",
        "    #print(\"$$$$$$$$$$$$$\")\n",
        "    sys_prompt = \"أنت كاتب مبدع وخبير في أدب الأطفال والناشئة. مختص في إنشاء الفصل التالي .يجب ان يحتوي الفصل التالي على 500 كلمة كحد أدنى\"\n",
        "    usr_prompt = f\"قم بإنشاء الفصل الاول استنادا فقط الى الفكرة الرئيسية: الفكرة الرئيسية للقصة هي {topic}.\\n\"\n",
        "    prompt = f\"{sys_prompt}\\n{usr_prompt}\"\n",
        "\n",
        "    # Tokenize with padding and return attention_mask\n",
        "    encoded_input = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
        "    #encoded_input = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    input_ids = encoded_input.input_ids\n",
        "    attention_mask = encoded_input.attention_mask\n",
        "    input_ids = encoded_input['input_ids'].to(device)\n",
        "    attention_mask = encoded_input['attention_mask'].to(device)\n",
        "\n",
        "    # Generate text with the attention mask explicitly provided\n",
        "    output_ids = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        max_length=128,        # Adjust this if you expect longer output\n",
        "        do_sample=True,        # Enable sampling for more creative text\n",
        "        top_k=50,              # Top-K sampling\n",
        "        top_p=0.95,            # Nucleus sampling\n",
        "        num_return_sequences=1, # Generate one sequence\n",
        "        temperature=0.0001,\n",
        "    )\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    input_ids = encoded_input['input_ids'].to(device)\n",
        "    attention_mask = encoded_input['attention_mask'].to(device)\n",
        "\n",
        "    # Decode the generated tokens to text\n",
        "    generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    # Return generated chapter content\n",
        "    #return f\"### Chapter 1: {generated_text}\"\n",
        "    new_chapter = generated_text[len(prompt):]\n",
        "    output_chapters.append(new_chapter)\n",
        "    # Print the generated chapter content\n",
        "    print(len(output_chapters))\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    return new_chapter\n",
        "\n",
        "def generate_next_chapter(topic, chapter_number):#, chapter2, chapter3):\n",
        "    print(\"\\n########### CHAPTER\", chapter_number, \"#############################\\n\")\n",
        "    global output_chapters\n",
        "    #topic = chapter1  # Using Chapter 1 input as topic\n",
        "    output_chapters = output_chapters[:int(chapter_number)-1]\n",
        "    print(len(output_chapters))\n",
        "    #previous_chapters = \"\\n\\n\".join(output_chapters[:int(chapter_number)-1])\n",
        "    previous_chapters = \"\\n\\n\".join(output_chapters)\n",
        "    print(\"**** Previous chapters ****\\n\", previous_chapters,'\\n')\n",
        "    #previous_chapters = \"\\n\\n\".join(output_chapters[:1])\n",
        "    sys_prompt = \"أنت كاتب مبدع وخبير في أدب الأطفال والناشئة. مختص في إنشاء الفصل التالي .يجب ان يحتوي الفصل التالي على 500 كلمة كحد أدنى\"\n",
        "    #usr_prompt = f\"قم بإنشاء الفصل الاول استنادا فقط الى الفكرة الرئيسية: الفكرة الرئيسية للقصة هي {topic}.\\n\"\n",
        "\n",
        "    usr_prompt = (\n",
        "            f\"باستخدام الفصول السابقة:\\n{previous_chapters}\\n\\n\"\n",
        "            f\"وبناءً على الفكرة الرئيسية للفصل {chapter_number}: '{topic}', قم بإنشاء الفصل {chapter_number}.\\n\"\n",
        "        )\n",
        "    prompt = f\"{sys_prompt}\\n{usr_prompt}\"\n",
        "\n",
        "    # Tokenize with padding and return attention_mask\n",
        "    #encoded_input = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=200)\n",
        "    encoded_input = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    input_ids = encoded_input.input_ids\n",
        "    attention_mask = encoded_input.attention_mask\n",
        "    input_ids = encoded_input['input_ids'].to(device)\n",
        "    attention_mask = encoded_input['attention_mask'].to(device)\n",
        "\n",
        "    # Generate text with the attention mask explicitly provided\n",
        "    output_ids = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        max_length=128 * int(chapter_number),        # Adjust this if you expect longer output\n",
        "        do_sample=True,        # Enable sampling for more creative text\n",
        "        top_k=50,              # Top-K sampling\n",
        "        top_p=0.95,            # Nucleus sampling\n",
        "        num_return_sequences=1, # Generate one sequence\n",
        "        temperature=0.0001,\n",
        "    )\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    input_ids = encoded_input['input_ids'].to(device)\n",
        "    attention_mask = encoded_input['attention_mask'].to(device)\n",
        "\n",
        "    # Decode the generated tokens to text\n",
        "    generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "    # Return generated chapter content\n",
        "    #return f\"### Chapter 1: {generated_text}\"\n",
        "    new_chapter = generated_text[len(prompt):]\n",
        "    output_chapters.append(new_chapter)\n",
        "    print(\"******** Chapter\", chapter_number, \"*********\\n\", new_chapter, '\\n')\n",
        "    print(len(output_chapters))\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    return new_chapter\n",
        "\n",
        "\n",
        "# Create Gradio interface for user input\n",
        "with gr.Blocks() as demo:\n",
        "    # Header or title for the interface\n",
        "    gr.Markdown(\"# مولد القصة التفاعلية \")\n",
        "\n",
        "    # Instructions or subheader\n",
        "    gr.Markdown(\"اكتب فكرتك لكل فصل\")\n",
        "\n",
        "    with gr.Tabs():  # Using tabs as shown in your design\n",
        "\n",
        "        with gr.TabItem(\"الفصل 1\"):\n",
        "            #chapter1_input = gr.Textbox(label=\"Chapter 1 Idea\", placeholder=\"Describe Chapter 1 here...\", lines=2)\n",
        "            #chapter1_input = gr.Textbox(\"فتاة فقيرة تسمى ميساء تعيش مع عمها و زوجته الشريرة\", label=\"Chapter 1 Idea\", placeholder=\"Describe Chapter 1 here...\", lines=2)\n",
        "            chapter1_input = gr.Textbox(\"يعيش احمد في منزل صغير في الصحراء\", label=\"فكرةالفصل 1\", placeholder=\"Describe الفصل 1 here...\", lines=2)\n",
        "            # Button to submit the data and generate the story\n",
        "            submit_button = gr.Button(\"انشاء الفصل 1\")\n",
        "            # Output area to display the generated content\n",
        "            output = gr.Textbox(label=\"انشاء الفصل 1\", interactive=False, lines=10)\n",
        "            # Button click action: Capture inputs and display the generated story\n",
        "            submit_button.click(generate_first_chapter, inputs= chapter1_input, outputs=output)\n",
        "\n",
        "\n",
        "        with gr.TabItem(\"الفصل 2\"):\n",
        "            #chapter_input = gr.Textbox(\"اروي الصعوبات الي تواجه ميساء نفسيا و ماديا و اسريا و التحديات الي تواجهها\", label=\"Chapter 2 Idea\", placeholder=\"Describe Chapter 2 here...\", lines=2)\n",
        "            chapter_input = gr.Textbox(\"عثور احمد على خريطه صدفه\", label=\" 2 فكرةالفصل \", placeholder=\"Describe الفصل 2 here...\", lines=2)\n",
        "            # Button to submit the data and generate the story\n",
        "            submit_button = gr.Button(\"انشاء الفصل 2\")\n",
        "\n",
        "            # Output area to display the generated content\n",
        "            output = gr.Textbox(label=\"انشاء الفصل 2\", interactive=False, lines=2)\n",
        "            #print(\"-------------\", output_chapters[0])\n",
        "            # Button click action: Capture inputs and display the generated story\n",
        "            #previous_chapters = \"\\n\\n\".join(output_chapters[:1])\n",
        "            submit_button.click(generate_next_chapter, inputs= [chapter_input, gr.State('2')], outputs=output)\n",
        "\n",
        "        with gr.TabItem(\"الفصل 3\"):\n",
        "            #chapter_input = gr.Textbox(\"وجدت ميساء كنزا في الحديقة و كيف تغير حالها و كيف انتقمت من زوجة عمها\", label=\"Chapter 3 Idea\", placeholder=\"Describe Chapter 3 here...\", lines=2)\n",
        "            chapter_input = gr.Textbox(\"الصعوبات التي واجهته\", label=\"فكرةالفصل 3 \", placeholder=\"Describe الفصل 3 here...\", lines=2)\n",
        "            # Button to submit the data and generate the story\n",
        "            submit_button = gr.Button(\"انشاء الفصل 3\")\n",
        "            # Output area to display the generated content\n",
        "            output = gr.Textbox(label=\"انشاء الفصل 3\", interactive=False, lines=2)\n",
        "            #print(\"-------------\", output_chapters[0])\n",
        "            # Button click action: Capture inputs and display the generated story\n",
        "            #previous_chapters = \"\\n\\n\".join(output_chapters[:1])\n",
        "            submit_button.click(generate_next_chapter, inputs= [chapter_input, gr.State('3')], outputs=output)\n",
        "\n",
        "        with gr.TabItem(\"الفصل 4\"):\n",
        "            #chapter_input = gr.Textbox(\"وجدت ميساء كنزا في الحديقة و كيف تغير حالها و كيف انتقمت من زوجة عمها\", label=\"Chapter 3 Idea\", placeholder=\"Describe Chapter 4 here...\", lines=2)\n",
        "            chapter_input = gr.Textbox(\"الملاك الذي انقذ احمد\", label=\"فكرةالفصل 4 \", placeholder=\"Describe الفصل 4 here...\", lines=2)\n",
        "            # Button to submit the data and generate the story\n",
        "            submit_button = gr.Button(\"انشاء الفصل  4 \")\n",
        "            # Output area to display the generated content\n",
        "            output = gr.Textbox(label=\"انشاء الفصل  4\", interactive=False, lines=2)\n",
        "            #print(\"-------------\", output_chapters[0])\n",
        "            # Button click action: Capture inputs and display the generated story\n",
        "            #previous_chapters = \"\\n\\n\".join(output_chapters[:1])\n",
        "            submit_button.click(generate_next_chapter, inputs= [chapter_input, gr.State('4')], outputs=output)\n",
        "        with gr.TabItem(\"الفصل 5\"):\n",
        "            chapter_input = gr.Textbox(\"عوده احمد الى المنزل بسلام يروي قصته\", label=\"فكرةالفصل 5 \", placeholder=\"Describe الفصل 5 here...\", lines=2)\n",
        "            # Button to submit the data and generate the story\n",
        "            submit_button = gr.Button(\"انشاء الفصل 5 \")\n",
        "            # Output area to display the generated content\n",
        "            output = gr.Textbox(label=\"انشاء الفصل 5\", interactive=False, lines=2)\n",
        "            #print(\"-------------\", output_chapters[0])\n",
        "            # Button click action: Capture inputs and display the generated story\n",
        "            #previous_chapters = \"\\n\\n\".join(output_chapters[:1])\n",
        "            submit_button.click(generate_next_chapter, inputs= [chapter_input, gr.State('5')], outputs=output)\n",
        "\n",
        "# Launch the interface\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5XiOvQosglvZ",
        "outputId": "512ecbea-4439-4548-9e2b-2243fc43227e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://38b8c4c3ffeb553578.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://38b8c4c3ffeb553578.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "########### CHAPTER 2 #############################\n",
            "\n",
            "1\n",
            "**** Previous chapters ****\n",
            " في قرية صغيرة تقع بين الكثبان الرملية، عاش أحمد مع أسرته في منزل بسيط تحيط به النخيل من كل جانب. كان أحمد يحب الطبيعة ويقضي ساعات طويلة في مراقبة الطيور وهي تحلق في السماء، بينما كان أحمد يستمتع بمشاهدة النجوم في السماء الصافية.\n",
            "\n",
            "في أحد الأيام، بينما كان أحمد يلعب في الفناء الخلفي لمنزله، لاحظ شيئًا غريب� \n",
            "\n",
            "******** Chapter 2 *********\n",
            " عاد أحمد إلى المنزل وهو يحمل خريطته القديمة بعناية. كان يشعر بشيء غريب، وكأن شيئًا ما يلمع في السماء. قرر أحمد أن يأخذ خريطته إلى صديقه المقرب، علي، ليكتشفا ما وجده.\n",
            "\n",
            "قال أحمد بحماس: \"علي، انظر ماذا وجدت!\"\n",
            "\n",
            "ابتسم علي وقال: \"هذه خريطة قديمة لمكان سري في الصحراء. يبدو أنها تشير إلى كنز مخفي!\"\n",
            "\n",
            "أجاب أحمد بحماس: \"لكن كيف سنصل إليه؟\"\n",
            "\n",
            "أجاب \n",
            "\n",
            "2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "########### CHAPTER 3 #############################\n",
            "\n",
            "2\n",
            "**** Previous chapters ****\n",
            " في قرية صغيرة تقع بين الكثبان الرملية، عاش أحمد مع أسرته في منزل بسيط تحيط به النخيل من كل جانب. كان أحمد يحب الطبيعة ويقضي ساعات طويلة في مراقبة الطيور وهي تحلق في السماء، بينما كان أحمد يستمتع بمشاهدة النجوم في السماء الصافية.\n",
            "\n",
            "في أحد الأيام، بينما كان أحمد يلعب في الفناء الخلفي لمنزله، لاحظ شيئًا غريب�\n",
            "\n",
            "عاد أحمد إلى المنزل وهو يحمل خريطته القديمة بعناية. كان يشعر بشيء غريب، وكأن شيئًا ما يلمع في السماء. قرر أحمد أن يأخذ خريطته إلى صديقه المقرب، علي، ليكتشفا ما وجده.\n",
            "\n",
            "قال أحمد بحماس: \"علي، انظر ماذا وجدت!\"\n",
            "\n",
            "ابتسم علي وقال: \"هذه خريطة قديمة لمكان سري في الصحراء. يبدو أنها تشير إلى كنز مخفي!\"\n",
            "\n",
            "أجاب أحمد بحماس: \"لكن كيف سنصل إليه؟\"\n",
            "\n",
            "أجاب \n",
            "\n",
            "******** Chapter 3 *********\n",
            " بعد أن وافق أحمد وعلي على الانضمام إلى أحمد في الرحلة، بدأا في تجهيز الأدوات اللازمة للرحلة. كان عليهما جمع بعض الماء والطعام والبوصلة وخريطة قديمة وجدها أحمد في مكتبة جده.\n",
            "\n",
            "في صباح اليوم التالي، انطلقا في طريقهما نحو الصحراء. كان الهواء منعشًا والشمس تشرق بلطف، مما أضفى جوًا من الغموض.\n",
            "\n",
            "عندما وصلا إلى النقطة التي حددتها الخريطة، بدأ أحمد وعلي في استكشاف الصحراء. كانت الرمال تمتد بلا نهاية تحت أقدامهم، مما أضفى شعورًا بالرهبة والإثارة على الرحلة.\n",
            "\n",
            "بينما كانا يسيران، لاحظا شيئ \n",
            "\n",
            "3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "########### CHAPTER 4 #############################\n",
            "\n",
            "3\n",
            "**** Previous chapters ****\n",
            " في قرية صغيرة تقع بين الكثبان الرملية، عاش أحمد مع أسرته في منزل بسيط تحيط به النخيل من كل جانب. كان أحمد يحب الطبيعة ويقضي ساعات طويلة في مراقبة الطيور وهي تحلق في السماء، بينما كان أحمد يستمتع بمشاهدة النجوم في السماء الصافية.\n",
            "\n",
            "في أحد الأيام، بينما كان أحمد يلعب في الفناء الخلفي لمنزله، لاحظ شيئًا غريب�\n",
            "\n",
            "عاد أحمد إلى المنزل وهو يحمل خريطته القديمة بعناية. كان يشعر بشيء غريب، وكأن شيئًا ما يلمع في السماء. قرر أحمد أن يأخذ خريطته إلى صديقه المقرب، علي، ليكتشفا ما وجده.\n",
            "\n",
            "قال أحمد بحماس: \"علي، انظر ماذا وجدت!\"\n",
            "\n",
            "ابتسم علي وقال: \"هذه خريطة قديمة لمكان سري في الصحراء. يبدو أنها تشير إلى كنز مخفي!\"\n",
            "\n",
            "أجاب أحمد بحماس: \"لكن كيف سنصل إليه؟\"\n",
            "\n",
            "أجاب\n",
            "\n",
            "بعد أن وافق أحمد وعلي على الانضمام إلى أحمد في الرحلة، بدأا في تجهيز الأدوات اللازمة للرحلة. كان عليهما جمع بعض الماء والطعام والبوصلة وخريطة قديمة وجدها أحمد في مكتبة جده.\n",
            "\n",
            "في صباح اليوم التالي، انطلقا في طريقهما نحو الصحراء. كان الهواء منعشًا والشمس تشرق بلطف، مما أضفى جوًا من الغموض.\n",
            "\n",
            "عندما وصلا إلى النقطة التي حددتها الخريطة، بدأ أحمد وعلي في استكشاف الصحراء. كانت الرمال تمتد بلا نهاية تحت أقدامهم، مما أضفى شعورًا بالرهبة والإثارة على الرحلة.\n",
            "\n",
            "بينما كانا يسيران، لاحظا شيئ \n",
            "\n",
            "******** Chapter 4 *********\n",
            " بعد ساعات من السير، لاحظا شيئًا لامعًا تحت الرمال. اقترب أحمد وعلي أكثر ليكتشفا أنه قطعة من الزجاج المكسور. كانت القطعة تبدو قديمة جدًا، لكنها تحمل نقوشًا غريبة.\n",
            "\n",
            "قال علي وهو يشير إلى النقوش: \"انظروا! إنها تبدو وكأنها جزء من خريطة!\"\n",
            "\n",
            "أجابت علي: \"ربما تكون هذه بداية مغامرة جديدة.\"\n",
            "\n",
            "بدأ الصديقان في فحص الخريطة بعناية، محاولين فهم الرموز والنقوش. كانت الرموز تبدو وكأنها تعليمات تقود إلى مكان معين.\n",
            "\n",
            "قال علي وهو يشير إلى الخريطة: \n",
            "\n",
            "4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "########### CHAPTER 5 #############################\n",
            "\n",
            "4\n",
            "**** Previous chapters ****\n",
            " في قرية صغيرة تقع بين الكثبان الرملية، عاش أحمد مع أسرته في منزل بسيط تحيط به النخيل من كل جانب. كان أحمد يحب الطبيعة ويقضي ساعات طويلة في مراقبة الطيور وهي تحلق في السماء، بينما كان أحمد يستمتع بمشاهدة النجوم في السماء الصافية.\n",
            "\n",
            "في أحد الأيام، بينما كان أحمد يلعب في الفناء الخلفي لمنزله، لاحظ شيئًا غريب�\n",
            "\n",
            "عاد أحمد إلى المنزل وهو يحمل خريطته القديمة بعناية. كان يشعر بشيء غريب، وكأن شيئًا ما يلمع في السماء. قرر أحمد أن يأخذ خريطته إلى صديقه المقرب، علي، ليكتشفا ما وجده.\n",
            "\n",
            "قال أحمد بحماس: \"علي، انظر ماذا وجدت!\"\n",
            "\n",
            "ابتسم علي وقال: \"هذه خريطة قديمة لمكان سري في الصحراء. يبدو أنها تشير إلى كنز مخفي!\"\n",
            "\n",
            "أجاب أحمد بحماس: \"لكن كيف سنصل إليه؟\"\n",
            "\n",
            "أجاب\n",
            "\n",
            "بعد أن وافق أحمد وعلي على الانضمام إلى أحمد في الرحلة، بدأا في تجهيز الأدوات اللازمة للرحلة. كان عليهما جمع بعض الماء والطعام والبوصلة وخريطة قديمة وجدها أحمد في مكتبة جده.\n",
            "\n",
            "في صباح اليوم التالي، انطلقا في طريقهما نحو الصحراء. كان الهواء منعشًا والشمس تشرق بلطف، مما أضفى جوًا من الغموض.\n",
            "\n",
            "عندما وصلا إلى النقطة التي حددتها الخريطة، بدأ أحمد وعلي في استكشاف الصحراء. كانت الرمال تمتد بلا نهاية تحت أقدامهم، مما أضفى شعورًا بالرهبة والإثارة على الرحلة.\n",
            "\n",
            "بينما كانا يسيران، لاحظا شيئ\n",
            "\n",
            "بعد ساعات من السير، لاحظا شيئًا لامعًا تحت الرمال. اقترب أحمد وعلي أكثر ليكتشفا أنه قطعة من الزجاج المكسور. كانت القطعة تبدو قديمة جدًا، لكنها تحمل نقوشًا غريبة.\n",
            "\n",
            "قال علي وهو يشير إلى النقوش: \"انظروا! إنها تبدو وكأنها جزء من خريطة!\"\n",
            "\n",
            "أجابت علي: \"ربما تكون هذه بداية مغامرة جديدة.\"\n",
            "\n",
            "بدأ الصديقان في فحص الخريطة بعناية، محاولين فهم الرموز والنقوش. كانت الرموز تبدو وكأنها تعليمات تقود إلى مكان معين.\n",
            "\n",
            "قال علي وهو يشير إلى الخريطة: \n",
            "\n",
            "******** Chapter 5 *********\n",
            " بعد أن تأكد من أن الخريطة صحيحة، عاد أحمد وعلي إلى المنزل. كانا متحمسين للغاية لرؤية ما وجداه. جلسا في غرفة المعيشة، وبدأا في سرد تفاصيل المغامرة التي تنتظرهما.\n",
            "\n",
            "قال أحمد وهو ينظر إلى الخريطة: \"هذه الخريطة تشير إلى مكان معين في الصحراء، حيث يمكن أن تكون هناك كنوز أو أسرار مخفية.\"\n",
            "\n",
            "أومأ علي برأسه مؤكدًا: \"علينا أن نكون حذرين، قد تكون هذه مجرد بداية لمغامرة لا تُنسى.\"\n",
            "\n",
            "بدأ الصديقان في سرد القصة قائلاً: \"في \n",
            "\n",
            "5\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://38b8c4c3ffeb553578.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_next_chapter())"
      ],
      "metadata": {
        "id": "FtkCAFytXG5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature 2: Question Answering"
      ],
      "metadata": {
        "id": "tSfTPE9n-Ggz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######\"child_question\": {\n",
        "#            \"role\": \"user\",\n",
        "#            \"content\": \"ما هو السر وراء لمعان ريش عصفور الشمس؟\"\n",
        "#        },\n",
        "#        \"chatbot_answer\": {\n",
        "#            \"role\": \"assistant\",\n",
        "#            \"content\": \"أهلاً بك! لمعان ريش عصفور الشمس يأتي من تميزه وجماله الفريد. يقال إن هذا العصفور يمتلك ريشًا مصنوعًا من الذهب، وهو ما يجعله يبدو مشعًا ومتألقًا تحت أشعة الشمس. اللمعان الذي يظهر من ريشه يعكس جماله الد\"\n",
        "#        }"
      ],
      "metadata": {
        "id": "92FQDYMn85EH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "story = \"\"\"### القصة:\n",
        "في قرية صغيرة محاطة بأشجار مورقة، عاش العصفور الصغير شموس بريشٍ ذهبي لامع. ذات صباحٍ مشرق، انضمت إليهم العصفورة الملونة درة، واقترحوا معًا الانطلاق للبحث عن النبع السري حيث يقيم الطائر الحكيم. انطلق الأصدقاء: شموس، درة، وعطوف، مليئين بالحماس والغناء.\n",
        "عند حافة الغابة الكثيفة، نبّههم عطوف إلى ضرورة التوازن بين الشجاعة والحذر، واتفقوا على البقاء معًا. دخلوا الظل الكثيف، فتلقّاهم غراب حكيم محذّرًا من المخاطر وشجّعهم على التعلم من التجربة. شكروا غرابه وتابعوا طريقهم حتى واجهوا نهرًا جارفًا. بعد تفكير جماعي، جلبوا غصنًا قويًا شكّل لهم جسرًا مؤقتًا، فنجحوا في عبوره رغم انزلاق شموس الذي أنقذه أصدقاؤه بسرعة.\n",
        "حين وصلوا إلى النبع السحري، استقبلهم الطائر الحكيم بريشٍ فضي وعيون لامعة. بيّن لهم أنّ الطيران العالي لا يقتصر على قوة الأجنحة فقط، بل ينبع من نقاء القلب وصفاء النية، وأنّ التعاون والوفاء هما جناحي الارتقاء إلى سماء الأحلام. أدرك الأصدقاء أن حكمة الحكيم تعكس دروس رحلتهم.\n",
        "عاد شموس ورفاقه إلى قريتهم حاملين الذكريات والعبر، وشاركوا أهل القرية تجاربهم عن العمل الجماعي والتغلب على الصعاب. أصبحت مغامرتهم مثالًا يُحتذى به، ملهمة لكل صغير وكبير للاستمرار في استكشاف عوالم جديدة بروح الوحدة والقيم النبيلة.\n",
        "###\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "_QVsTYioMIKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "story=\"\"\"### القصة:\n",
        "\n",
        " في قرية صغيرة تقع بين الكثبان الرملية، عاش أحمد مع أسرته في منزل بسيط تحيط به النخيل من كل جانب. كان أحمد يحب الطبيعة ويقضي ساعات طويلة في مراقبة الطيور وهي تحلق في السماء، بينما كان أحمد يستمتع بمشاهدة النجوم في السماء الصافية.\n",
        "\n",
        "في أحد الأيام، بينما كان أحمد يلعب في الفناء الخلفي لمنزله، لاحظ شيئًا غريب�\n",
        "\n",
        "عاد أحمد إلى المنزل وهو يحمل خريطته القديمة بعناية. كان يشعر بشيء غريب، وكأن شيئًا ما يلمع في السماء. قرر أحمد أن يأخذ خريطته إلى صديقه المقرب، علي، ليكتشفا ما وجده.\n",
        "\n",
        "قال أحمد بحماس: \"علي، انظر ماذا وجدت!\"\n",
        "\n",
        "ابتسم علي وقال: \"هذه خريطة قديمة لمكان سري في الصحراء. يبدو أنها تشير إلى كنز مخفي!\"\n",
        "\n",
        "أجاب أحمد بحماس: \"لكن كيف سنصل إليه؟\"\n",
        "\n",
        "أجاب\n",
        "\n",
        "بعد أن وافق أحمد وعلي على الانضمام إلى أحمد في الرحلة، بدأا في تجهيز الأدوات اللازمة للرحلة. كان عليهما جمع بعض الماء والطعام والبوصلة وخريطة قديمة وجدها أحمد في مكتبة جده.\n",
        "\n",
        "في صباح اليوم التالي، انطلقا في طريقهما نحو الصحراء. كان الهواء منعشًا والشمس تشرق بلطف، مما أضفى جوًا من الغموض.\n",
        "\n",
        "عندما وصلا إلى النقطة التي حددتها الخريطة، بدأ أحمد وعلي في استكشاف الصحراء. كانت الرمال تمتد بلا نهاية تحت أقدامهم، مما أضفى شعورًا بالرهبة والإثارة على الرحلة.\n",
        "\n",
        "بينما كانا يسيران، لاحظا شيئ\n",
        "\n",
        "بعد ساعات من السير، لاحظا شيئًا لامعًا تحت الرمال. اقترب أحمد وعلي أكثر ليكتشفا أنه قطعة من الزجاج المكسور. كانت القطعة تبدو قديمة جدًا، لكنها تحمل نقوشًا غريبة.\n",
        "\n",
        "قال علي وهو يشير إلى النقوش: \"انظروا! إنها تبدو وكأنها جزء من خريطة!\"\n",
        "\n",
        "أجابت علي: \"ربما تكون هذه بداية مغامرة جديدة.\"\n",
        "\n",
        "بدأ الصديقان في فحص الخريطة بعناية، محاولين فهم الرموز والنقوش. كانت الرموز تبدو وكأنها تعليمات تقود إلى مكان معين.\n",
        "\n",
        "قال علي وهو يشير إلى الخريطة:\n",
        " بعد أن تأكد من أن الخريطة صحيحة، عاد أحمد وعلي إلى المنزل. كانا متحمسين للغاية لرؤية ما وجداه. جلسا في غرفة المعيشة، وبدأا في سرد تفاصيل المغامرة التي تنتظرهما.\n",
        "\n",
        "قال أحمد وهو ينظر إلى الخريطة: \"هذه الخريطة تشير إلى مكان معين في الصحراء، حيث يمكن أن تكون هناك كنوز أو أسرار مخفية.\"\n",
        "\n",
        "أومأ علي برأسه مؤكدًا: \"علينا أن نكون حذرين، قد تكون هذه مجرد بداية لمغامرة لا تُنسى.\"\n",
        "\n",
        "بدأ الصديقان في سرد القصة قائلاً: \"في\n",
        "\n",
        "###\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "fNpDtqeBXnRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_question(question):\n",
        "\n",
        "    #sys_prompt = f\"أنت تلعب دور أحمد:\\n{story}. مهمتك هي الإجابة على الأسئلة التي تُطرح عليك\"\n",
        "    sys_prompt = f\"أنت تلعب دور أحمد\\n. مهمتك هي الإجابة على الأسئلة التي تُطرح عليك حول القصة.\\n{story}\"\n",
        "    #usr_prompt = f\"اجب عن السؤال التالي :  {question}.\\n\"\n",
        "    usr_prompt = f\"اجب عن السؤال التالي:\\n### السؤال:\\n{question}\\n\\n### الجواب:\\n\"\n",
        "    prompt = f\"{sys_prompt}\\n{usr_prompt}\"\n",
        "    #print (\"prompt\", prompt)\n",
        "    # Tokenize with padding and return attention_mask\n",
        "    #encoded_input = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
        "    encoded_input = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    input_ids = encoded_input.input_ids\n",
        "    attention_mask = encoded_input.attention_mask\n",
        "    input_ids = encoded_input['input_ids'].to(device)\n",
        "    attention_mask = encoded_input['attention_mask'].to(device)\n",
        "\n",
        "    # Generate text with the attention mask explicitly provided\n",
        "    output_ids = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        #max_length=1500,        # Adjust this if you expect longer output\n",
        "        do_sample=True,        # Enable sampling for more creative text\n",
        "        top_k=50,              # Top-K sampling\n",
        "        top_p=0.95,            # Nucleus sampling\n",
        "        num_return_sequences=1, # Generate one sequence\n",
        "        #temperature=0.00001,\n",
        "\n",
        "    )\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    input_ids = encoded_input['input_ids'].to(device)\n",
        "    attention_mask = encoded_input['attention_mask'].to(device)\n",
        "\n",
        "    # Decode the generated tokens to text\n",
        "    generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "    answer = generated_text[len(prompt):]\n",
        "    #print (answer)\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    return answer\n",
        "\n",
        "\n",
        "\n",
        "# Create Gradio interface for user input\n",
        "with gr.Blocks() as demo:\n",
        "    # Header or title for the interface\n",
        "    gr.Markdown(\"# مولد القصة التفاعلية \")\n",
        "\n",
        "    # Instructions or subheader\n",
        "    gr.Markdown(\"اكتب سؤالك\")\n",
        "\n",
        "    with gr.Tabs():  # Using tabs as shown in your design\n",
        "\n",
        "        with gr.TabItem(\"Question_Answer\"):\n",
        "            #chapter1_input = gr.Textbox(label=\"Chapter 1 Idea\", placeholder=\"Describe Chapter 1 here...\", lines=2)\n",
        "            question_input = gr.Textbox(label=\"Question\", placeholder=\"Write your question...\", lines=2)\n",
        "            # Button to submit the data and generate the story\n",
        "            submit_button = gr.Button(\"Get Answer\")\n",
        "            # Output area to display the generated content\n",
        "            output = gr.Textbox(label=\"Answer\", interactive=False, lines=10)\n",
        "            # Button click action: Capture inputs and display the generated story\n",
        "            submit_button.click(answer_question, inputs= question_input, outputs=output)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Launch the interface\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "id": "T0y-ULDc4GCJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "outputId": "fb1b5620-7d41-4206-a5ae-242d934bdf26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://2e31773da910aed2d0.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://2e31773da910aed2d0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://2e31773da910aed2d0.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature 3 : Modify the story"
      ],
      "metadata": {
        "id": "wxvWO7R_N95m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def modified_story(modification):\n",
        "\n",
        "    sys_prompt = f\" حسب الطلب \\n{story} مهمتك هي تغيير القصة .\"\n",
        "    usr_prompt = f\" الطلب:  {modification}.\\n\"\n",
        "    prompt = f\"{sys_prompt}\\n{usr_prompt}\"\n",
        "    print (\"prompt\", prompt)\n",
        "    # Tokenize with padding and return attention_mask\n",
        "    #encoded_input = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
        "    encoded_input = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    input_ids = encoded_input.input_ids\n",
        "    attention_mask = encoded_input.attention_mask\n",
        "    input_ids = encoded_input['input_ids'].to(device)\n",
        "    attention_mask = encoded_input['attention_mask'].to(device)\n",
        "\n",
        "    # Generate text with the attention mask explicitly provided\n",
        "    output_ids = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        #max_length=128,        # Adjust this if you expect longer output\n",
        "        do_sample=True,        # Enable sampling for more creative text\n",
        "        top_k=50,              # Top-K sampling\n",
        "        top_p=0.95,            # Nucleus sampling\n",
        "        num_return_sequences=1, # Generate one sequence\n",
        "    )\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    input_ids = encoded_input['input_ids'].to(device)\n",
        "    attention_mask = encoded_input['attention_mask'].to(device)\n",
        "\n",
        "    # Decode the generated tokens to text\n",
        "    generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "    answer = generated_text[len(prompt):]\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    return answer\n",
        "\n",
        "\n",
        "\n",
        "# Create Gradio interface for user input\n",
        "with gr.Blocks() as demo:\n",
        "    # Header or title for the interface\n",
        "    gr.Markdown(\"# Interactive Story Generator\")\n",
        "\n",
        "    # Instructions or subheader\n",
        "    gr.Markdown(\"Enter your ideas for each chapter.\")\n",
        "\n",
        "    with gr.Tabs():  # Using tabs as shown in your design\n",
        "\n",
        "        with gr.TabItem(\"Modify Story\"):\n",
        "            #chapter1_input = gr.Textbox(label=\"Chapter 1 Idea\", placeholder=\"Describe Chapter 1 here...\", lines=2)\n",
        "            question_input = gr.Textbox(label=\"Modification\", placeholder=\"Write your modification...\", lines=2)\n",
        "            # Button to submit the data and generate the story\n",
        "            submit_button = gr.Button(\"Get Answer\")\n",
        "            # Output area to display the generated content\n",
        "            output = gr.Textbox(label=\"Story modified\", interactive=False, lines=10)\n",
        "            # Button click action: Capture inputs and display the generated story\n",
        "            submit_button.click(modified_story, inputs= question_input, outputs=output)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Launch the interface\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "id": "gfDNM89pOJ74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fca7eace-d31d-4247-9958-ee44ee549d39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://399e200568cc9bd1c0.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://399e200568cc9bd1c0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt  حسب الطلب \n",
            "### القصة:\n",
            "\n",
            " في قرية صغيرة تقع بين الكثبان الرملية، عاش أحمد مع أسرته في منزل بسيط تحيط به النخيل من كل جانب. كان أحمد يحب الطبيعة ويقضي ساعات طويلة في مراقبة الطيور وهي تحلق في السماء، بينما كان أحمد يستمتع بمشاهدة النجوم في السماء الصافية.\n",
            "\n",
            "في أحد الأيام، بينما كان أحمد يلعب في الفناء الخلفي لمنزله، لاحظ شيئًا غريب�\n",
            "\n",
            "عاد أحمد إلى المنزل وهو يحمل خريطته القديمة بعناية. كان يشعر بشيء غريب، وكأن شيئًا ما يلمع في السماء. قرر أحمد أن يأخذ خريطته إلى صديقه المقرب، علي، ليكتشفا ما وجده.\n",
            "\n",
            "قال أحمد بحماس: \"علي، انظر ماذا وجدت!\"\n",
            "\n",
            "ابتسم علي وقال: \"هذه خريطة قديمة لمكان سري في الصحراء. يبدو أنها تشير إلى كنز مخفي!\"\n",
            "\n",
            "أجاب أحمد بحماس: \"لكن كيف سنصل إليه؟\"\n",
            "\n",
            "أجاب\n",
            "\n",
            "بعد أن وافق أحمد وعلي على الانضمام إلى أحمد في الرحلة، بدأا في تجهيز الأدوات اللازمة للرحلة. كان عليهما جمع بعض الماء والطعام والبوصلة وخريطة قديمة وجدها أحمد في مكتبة جده.\n",
            "\n",
            "في صباح اليوم التالي، انطلقا في طريقهما نحو الصحراء. كان الهواء منعشًا والشمس تشرق بلطف، مما أضفى جوًا من الغموض.\n",
            "\n",
            "عندما وصلا إلى النقطة التي حددتها الخريطة، بدأ أحمد وعلي في استكشاف الصحراء. كانت الرمال تمتد بلا نهاية تحت أقدامهم، مما أضفى شعورًا بالرهبة والإثارة على الرحلة.\n",
            "\n",
            "بينما كانا يسيران، لاحظا شيئ\n",
            "\n",
            "بعد ساعات من السير، لاحظا شيئًا لامعًا تحت الرمال. اقترب أحمد وعلي أكثر ليكتشفا أنه قطعة من الزجاج المكسور. كانت القطعة تبدو قديمة جدًا، لكنها تحمل نقوشًا غريبة.\n",
            "\n",
            "قال علي وهو يشير إلى النقوش: \"انظروا! إنها تبدو وكأنها جزء من خريطة!\"\n",
            "\n",
            "أجابت علي: \"ربما تكون هذه بداية مغامرة جديدة.\"\n",
            "\n",
            "بدأ الصديقان في فحص الخريطة بعناية، محاولين فهم الرموز والنقوش. كانت الرموز تبدو وكأنها تعليمات تقود إلى مكان معين.\n",
            "\n",
            "قال علي وهو يشير إلى الخريطة: \n",
            " بعد أن تأكد من أن الخريطة صحيحة، عاد أحمد وعلي إلى المنزل. كانا متحمسين للغاية لرؤية ما وجداه. جلسا في غرفة المعيشة، وبدأا في سرد تفاصيل المغامرة التي تنتظرهما.\n",
            "\n",
            "قال أحمد وهو ينظر إلى الخريطة: \"هذه الخريطة تشير إلى مكان معين في الصحراء، حيث يمكن أن تكون هناك كنوز أو أسرار مخفية.\"\n",
            "\n",
            "أومأ علي برأسه مؤكدًا: \"علينا أن نكون حذرين، قد تكون هذه مجرد بداية لمغامرة لا تُنسى.\"\n",
            "\n",
            "بدأ الصديقان في سرد القصة قائلاً: \"في \n",
            "\n",
            "###\n",
            " مهمتك هي تغيير القصة .\n",
            " الطلب:  أبدل أحمد بعلي .\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt  حسب الطلب \n",
            "### القصة:\n",
            "\n",
            " في قرية صغيرة تقع بين الكثبان الرملية، عاش أحمد مع أسرته في منزل بسيط تحيط به النخيل من كل جانب. كان أحمد يحب الطبيعة ويقضي ساعات طويلة في مراقبة الطيور وهي تحلق في السماء، بينما كان أحمد يستمتع بمشاهدة النجوم في السماء الصافية.\n",
            "\n",
            "في أحد الأيام، بينما كان أحمد يلعب في الفناء الخلفي لمنزله، لاحظ شيئًا غريب�\n",
            "\n",
            "عاد أحمد إلى المنزل وهو يحمل خريطته القديمة بعناية. كان يشعر بشيء غريب، وكأن شيئًا ما يلمع في السماء. قرر أحمد أن يأخذ خريطته إلى صديقه المقرب، علي، ليكتشفا ما وجده.\n",
            "\n",
            "قال أحمد بحماس: \"علي، انظر ماذا وجدت!\"\n",
            "\n",
            "ابتسم علي وقال: \"هذه خريطة قديمة لمكان سري في الصحراء. يبدو أنها تشير إلى كنز مخفي!\"\n",
            "\n",
            "أجاب أحمد بحماس: \"لكن كيف سنصل إليه؟\"\n",
            "\n",
            "أجاب\n",
            "\n",
            "بعد أن وافق أحمد وعلي على الانضمام إلى أحمد في الرحلة، بدأا في تجهيز الأدوات اللازمة للرحلة. كان عليهما جمع بعض الماء والطعام والبوصلة وخريطة قديمة وجدها أحمد في مكتبة جده.\n",
            "\n",
            "في صباح اليوم التالي، انطلقا في طريقهما نحو الصحراء. كان الهواء منعشًا والشمس تشرق بلطف، مما أضفى جوًا من الغموض.\n",
            "\n",
            "عندما وصلا إلى النقطة التي حددتها الخريطة، بدأ أحمد وعلي في استكشاف الصحراء. كانت الرمال تمتد بلا نهاية تحت أقدامهم، مما أضفى شعورًا بالرهبة والإثارة على الرحلة.\n",
            "\n",
            "بينما كانا يسيران، لاحظا شيئ\n",
            "\n",
            "بعد ساعات من السير، لاحظا شيئًا لامعًا تحت الرمال. اقترب أحمد وعلي أكثر ليكتشفا أنه قطعة من الزجاج المكسور. كانت القطعة تبدو قديمة جدًا، لكنها تحمل نقوشًا غريبة.\n",
            "\n",
            "قال علي وهو يشير إلى النقوش: \"انظروا! إنها تبدو وكأنها جزء من خريطة!\"\n",
            "\n",
            "أجابت علي: \"ربما تكون هذه بداية مغامرة جديدة.\"\n",
            "\n",
            "بدأ الصديقان في فحص الخريطة بعناية، محاولين فهم الرموز والنقوش. كانت الرموز تبدو وكأنها تعليمات تقود إلى مكان معين.\n",
            "\n",
            "قال علي وهو يشير إلى الخريطة: \n",
            " بعد أن تأكد من أن الخريطة صحيحة، عاد أحمد وعلي إلى المنزل. كانا متحمسين للغاية لرؤية ما وجداه. جلسا في غرفة المعيشة، وبدأا في سرد تفاصيل المغامرة التي تنتظرهما.\n",
            "\n",
            "قال أحمد وهو ينظر إلى الخريطة: \"هذه الخريطة تشير إلى مكان معين في الصحراء، حيث يمكن أن تكون هناك كنوز أو أسرار مخفية.\"\n",
            "\n",
            "أومأ علي برأسه مؤكدًا: \"علينا أن نكون حذرين، قد تكون هذه مجرد بداية لمغامرة لا تُنسى.\"\n",
            "\n",
            "بدأ الصديقان في سرد القصة قائلاً: \"في \n",
            "\n",
            "###\n",
            " مهمتك هي تغيير القصة .\n",
            " الطلب:  أبدل أحمد بعلي .\n",
            "\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://399e200568cc9bd1c0.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vLOjaxkDQqTw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}